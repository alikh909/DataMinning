{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.\tDataset Overview "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "â€¢\tReintroduce your problem and dataset context from P1. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2297,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from scipy.stats import skew, kurtosis\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder, MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = \"./uae_used_cars_10k.csv\"\n",
    "data = pd.read_csv(file_path)\n",
    "row,col=data.shape\n",
    "print(f\"The number of attribute and records {data.shape}\")\n",
    "\n",
    "\n",
    "print(f\"Memory Usage: {data.memory_usage(deep=True).sum()/1024**2 :.2f} MB\")\n",
    "\n",
    "print(\"\\n\\nThe format of Data is .csv which sprete it by comma \")\n",
    "\n",
    "\n",
    "# print(data.head(5))\n",
    "# display(data.info())\n",
    "print(\"\\nTotal empty data for all attribute\")\n",
    "display(data.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-- Apply univirante studing all non_numeric data\n",
    "\n",
    "1-Model\n",
    "\n",
    "2-Make\n",
    "\n",
    "3-Boady Type\n",
    "\n",
    "4-Transmission\n",
    "\n",
    "5-Color\n",
    "\n",
    "6-Location\n",
    "\n",
    "7-Fuel Type\n",
    "\n",
    "8-Cylinder\n",
    "\n",
    "\n",
    "We will see the mode and freq Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ColumeName =[\"Model\",\"Make\",\"Body Type\",\"Transmission\",\"Color\",\"Location\",\"Fuel Type\",\"Cylinders\"]\n",
    "\n",
    "for i in ColumeName:\n",
    " \n",
    "    print(f\"The mode is {data[i].mode()[0]}\")\n",
    "    freq_table =data[i].value_counts()\n",
    "    print(freq_table)\n",
    "    print(\"------\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Apply univirante for numiric data\n",
    "\n",
    "apply it for\n",
    "\n",
    "1-Year\n",
    "\n",
    "2-price\n",
    "\n",
    "3-Millage\n",
    "\n",
    "We will find statical for numiric data such as\n",
    "1-mean\n",
    "2-meadian\n",
    "3-vence \n",
    "4-Mad\n",
    "5-Standard division\n",
    "6-range\n",
    "7-Q1\n",
    "8-Q3\n",
    "9-IQR\n",
    "10-higger fernce \n",
    "11-lowe fernce "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ColumnName=data.select_dtypes(include=['float64','int64']).columns\n",
    "\n",
    "for i in ColumnName:\n",
    "    print(f\"{i.upper()}\")\n",
    "    mean = data[i].mean()\n",
    "    meadian=data[i].median()\n",
    "    max=data[i].max()\n",
    "    range=data[i].max()-data[i].min()\n",
    "    min=data[i].min()\n",
    "    Q1 = data[i].quantile(0.25)\n",
    "    Q2 = data[i].quantile(0.50)\n",
    "    Q3 = data[i].quantile(0.75)\n",
    "    IQR = Q3 - Q1 \n",
    "    verance = data[i].var()\n",
    "    standered = data[i].std()\n",
    "    mad = (data[i] - data[i].mean()).abs().mean()\n",
    "    FenceQ1=Q1-(1.5*IQR)\n",
    "    FenceQ3=Q3+(1.5*IQR)\n",
    "    AboveHighFence3=(data[i]>FenceQ3).sum()\n",
    "    BelowLowFence1=(data[i]<FenceQ1).sum()\n",
    "\n",
    "    print(f\"For {i} collumn we found\")\n",
    "    \n",
    "    print(f\"Mean is: {mean}\")\n",
    "    print(f\"Meadian is: {meadian}\")\n",
    "    print(f\"min        {min}\")\n",
    "    print(F\"Q1    %25  {Q1}\")\n",
    "    print(F\"Q2    %50  {Q2}\")\n",
    "    print(F\"Q3    %75  {Q3}\")\n",
    "    print(f\"max        {max}\")\n",
    "\n",
    "    print(f\"IQR is {IQR}\")\n",
    "    print(f\"The range is {range}\")\n",
    "    print(f\"Verance is {verance}\")\n",
    "    print(f\"Standard dicision is {standered}\")\n",
    "    print(f\"Mad is {mad}\")\n",
    "\n",
    "    print(\"From using Fence Law to see outliers\")\n",
    "    print(f\"Data that below Q1 which is {FenceQ1} then we have {BelowLowFence1} outliers \")\n",
    "    print(f\"Data that above Q3 which is {FenceQ3} then we have {AboveHighFence3} outliers \")\n",
    "    print(\"-----------------------------------------\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ColumnName=['Cylinders','Color','Transmission'] \n",
    "title=['','Precip Type Frequancy','Transmission Type Frequancy']\n",
    "t=0\n",
    "for i in ColumnName:\n",
    "    count =data[i].value_counts()\n",
    "    plt.figure(figsize=(10,6))\n",
    "    count.plot(kind='bar',color=['darkblue','orange'])\n",
    "    plt.title(title[t])\n",
    "    plt.yticks(np.arange(0, count.max()+5,2000))\n",
    "    t+=1\n",
    "    plt.xlabel(i)\n",
    "    plt.ylabel('count')\n",
    "    \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "count = data['Fuel Type'].value_counts()\n",
    "\n",
    "plt.figure(figsize=(8,5))\n",
    "plt.hist(data['Fuel Type'], bins=30, color='darkblue', edgecolor='black')\n",
    "plt.title('Histogram of Body Type')\n",
    "plt.xlabel('Cylinders')\n",
    "plt.ylabel('Frequancy')\n",
    "plt.grid(True, linestyle='--', alpha=0.6)\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(8,5))\n",
    "data['Year'].plot(kind='density', color='orange', linewidth=2)\n",
    "\n",
    "plt.title('Density plot for Year')\n",
    "plt.xlabel('Year')\n",
    "plt.ylabel('Density')\n",
    "plt.grid(True, linestyle='--', alpha=0.6)\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(8,4))\n",
    "plt.boxplot(\n",
    "    data['Price'],\n",
    "    vert=False,\n",
    "    patch_artist=True,\n",
    "    boxprops=dict(facecolor='lightgreen', color='black'),\n",
    "    medianprops=dict(color='red'),\n",
    "    whiskerprops=dict(color='black'),\n",
    "    capprops=dict(color='black'),\n",
    "    flierprops=dict(marker='o', color='blue', alpha=0.5)\n",
    ")\n",
    "plt.title('Boxplot of Price')\n",
    "plt.xlabel('Price')\n",
    "plt.grid(True, linestyle='--', alpha=0.6)\n",
    "plt.show()\n",
    "\n",
    "temp = data['Price'].dropna() \n",
    "plt.figure(figsize=(12,6))\n",
    "stats.probplot(temp, dist=\"norm\", plot=plt)\n",
    "plt.title('Price')\n",
    "plt.grid(True, linestyle='--', alpha=0.6)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2303,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# # --- Define columns ---\n",
    "# FirstColumn = 'Price'\n",
    "# # SecoundColumn = 'Mileage'\n",
    "# SecoundColumn = 'Year'\n",
    "\n",
    "\n",
    "# # --- Filter for Toyota Camry only ---\n",
    "# brand_col = 'Make'\n",
    "# model_col = 'Model'\n",
    "# engineType = 'Cylinders'\n",
    "# Gear = 'Transmission'\n",
    "\n",
    "\n",
    "\n",
    "# filtered_data = data[\n",
    "#     (data[brand_col].str.lower() == 'toyota') \n",
    "#     & (data[model_col].str.lower() == 'camry')\n",
    "# ]\n",
    "\n",
    "\n",
    "\n",
    "# # --- Scatter plot ---\n",
    "# plt.figure(figsize=(4,4))\n",
    "# plt.scatter(\n",
    "#     filtered_data[FirstColumn],\n",
    "#     filtered_data[SecoundColumn],\n",
    "#     color='darkgreen', alpha=0.2, s=10, marker='o', edgecolors='none'\n",
    "# )\n",
    "\n",
    "# plt.title(f'Scatter Plot: {FirstColumn} vs {SecoundColumn} (mercedes-benz)', fontsize=16)\n",
    "# plt.xlabel(FirstColumn, fontsize=12)\n",
    "# plt.ylabel(SecoundColumn, fontsize=12)\n",
    "# plt.grid(True, linestyle='--', alpha=0.4)\n",
    "# plt.tight_layout()\n",
    "# plt.show()\n",
    "\n",
    "# # --- Covariance & Correlation on filtered data ---\n",
    "# Convariance = filtered_data[[FirstColumn, SecoundColumn]].cov()\n",
    "# Correlation = filtered_data[[FirstColumn, SecoundColumn]].corr()\n",
    "# cov = filtered_data[FirstColumn].cov(filtered_data[SecoundColumn])\n",
    "# cor = filtered_data[FirstColumn].corr(filtered_data[SecoundColumn])\n",
    "\n",
    "# print(filtered_data[FirstColumn].dtype)\n",
    "# print(filtered_data[SecoundColumn].dtype)\n",
    "\n",
    "\n",
    "# 4\n",
    "\n",
    "# print('Covariance:\\n', Convariance)\n",
    "# print('\\nCorrelation:\\n', Correlation)\n",
    "# print(f'\\nSingle values -> Cov: {cov:.4f}, Corr: {cor:.4f}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__ Now we will see Relationship between Type Boday with Transmision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from scipy.stats import chi2_contingency\n",
    "\n",
    "\n",
    "table =pd.crosstab(data['Body Type'],data['Transmission'])\n",
    "chi2, p, dof, expected = chi2_contingency(table)\n",
    "\n",
    "print(\"Chi-square Statistic:\", round(chi2, 2))\n",
    "print('-------------')\n",
    "print('contingency table\\n',table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from matplotlib.ticker import FuncFormatter\n",
    "\n",
    "selected_bodies = ['SUV', 'Sedan', 'Coupe', 'Pickup'] \n",
    "filtered_data = data[data['Body Type'].isin(selected_bodies)]\n",
    "\n",
    "plt.figure(figsize=(8, 5))\n",
    "filtered_data.boxplot(\n",
    "    column='Price',\n",
    "    by='Body Type',\n",
    "    patch_artist=True,\n",
    "    boxprops=dict(facecolor='lightblue', color='gray'),\n",
    "    medianprops=dict(color='red', linewidth=2),\n",
    ")\n",
    "\n",
    "plt.title('Price by Body Type', fontsize=14)\n",
    "plt.suptitle('')\n",
    "plt.xlabel('Body Type', fontsize=12)\n",
    "plt.ylabel('Price (AED)', fontsize=12)\n",
    "\n",
    "plt.grid(True, linestyle='--', alpha=0.6)\n",
    "# ðŸ‘‡ Format y-axis with commas\n",
    "plt.axhline(y=502_591, color='green', linestyle='-', linewidth=2, label='Outlier Threshold (502,591 AED)')\n",
    "\n",
    "plt.gca().yaxis.set_major_formatter(FuncFormatter(lambda x, _: f'{int(x):,}'))\n",
    "\n",
    "plt.show()\n",
    "\n",
    "print(\"The body Type that the price above 502,591 which is green line is an outliers \")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "filtered_data = data[(data['Make'] == 'mercedes-benz') & (data['Model'] == 'g-class')]\n",
    "\n",
    "corr_matrix = filtered_data[['Price', 'Mileage', 'Year']].corr()\n",
    "\n",
    "print(\"Correlation Matrix (Nissan Patrol only):\")\n",
    "print(round(corr_matrix, 2))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_theme(style=\"whitegrid\")\n",
    "\n",
    "filtered_data = data[(data['Make'] == 'nissan') & (data['Model'] == 'patrol')]\n",
    "\n",
    "plt.figure(figsize=(7, 5))\n",
    "sns.scatterplot(\n",
    "    data=filtered_data,\n",
    "    x='Price',\n",
    "    y='Mileage',\n",
    "    hue='Year',  \n",
    "    palette='coolwarm',\n",
    "    alpha=0.7,\n",
    "    edgecolor='k',\n",
    "    s=40\n",
    ")\n",
    "\n",
    "plt.title(\"Scatter Plot: Price vs Mileage (Colored by Year)\", fontsize=13, fontweight='bold')\n",
    "plt.xlabel(\"Price\")\n",
    "plt.ylabel(\"Mileage\")\n",
    "plt.legend(title=\"Year\", loc=\"upper right\")\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "row,col=data.shape\n",
    "print(f\"The number of attribute {col}\")\n",
    "print(f\"The number of record {row}\")\n",
    "\n",
    "\n",
    "print(\"\\n\\nThe format of Data is .csv which sprete it by comma \")\n",
    "\n",
    "print(\"The data type \")\n",
    "data.head(5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------> Here Start Preprosseing and Tranformtions <------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.\tPreprocessing and Transformation \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "â€¢\tHandle missing values (justify imputation or removal choices). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"All attributes with missing values:\")\n",
    "\n",
    "display(data.isnull().sum())\n",
    "\n",
    "missing = data.isnull().sum()[data.isnull().sum() > 0]\n",
    "print(missing)\n",
    "after_rows = data.shape[0]\n",
    "print(f\"Number of rows: {after_rows}\")\n",
    "\n",
    "\n",
    "if missing.shape[0] > 0:\n",
    "    print(\"I will handle it by removing rows with missing 'Cylinders' values\")\n",
    "\n",
    "    if 'Cylinders' in data.columns:\n",
    "        before_rows = data.shape[0]\n",
    "        data = data.dropna(subset=['Cylinders'])\n",
    "        after_rows = data.shape[0]\n",
    "        removed = before_rows - after_rows\n",
    "        print(f\"Removed {removed} rows that had missing 'Cylinders' values.\")\n",
    "        print(f\"Remaining rows after removal: {after_rows}\")\n",
    "    else:\n",
    "        print(\"Cylinders' column not found in dataset.\")\n",
    "else:\n",
    "    print('No missing values found.')\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(justify imputation or removal choices) \n",
    "\n",
    "I use removal row of that has missing value of 6 Cylinders because from EDA we see that mode distance from 8 Cylinder and 6 Cylinder not far \n",
    "\n",
    "6 Cylinder has 3420\n",
    "\n",
    "8 Cylinder has 3003\n",
    "\n",
    "We Use removal to not effect the data and make predication more accarancy "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "â€¢\tIdentify and address outliers or noise. \n",
    "\n",
    "From EDA We know that we have outliers for only price which is \n",
    "\n",
    "Price =1100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "# --- Boxplot: visualize before handling outliers ---\n",
    "plt.figure(figsize=(6,4))\n",
    "plt.boxplot(data['Price'])\n",
    "plt.title('Price Before Outlier Detection')\n",
    "plt.ylabel('Price (AED)')\n",
    "plt.show()\n",
    "\n",
    "# --- Calculate IQR and fences ---\n",
    "Q1 = data['Price'].quantile(0.25)\n",
    "Q3 = data['Price'].quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "\n",
    "lower_limit = Q1 - 1.5 * IQR\n",
    "upper_limit = Q3 + 1.5 * IQR\n",
    "\n",
    "print(f\"Lower fence: {lower_limit:.2f}\")\n",
    "print(f\"Upper fence: {upper_limit:.2f}\")\n",
    "\n",
    "# --- Detect all outliers ---\n",
    "outliers = data[data['Price'] > upper_limit]\n",
    "\n",
    "# --- Sort descending by price ---\n",
    "outliers_sorted = outliers.sort_values(by='Price', ascending=False)\n",
    "\n",
    "# --- Get top 4 most expensive cars ---\n",
    "top4_highest = outliers_sorted.head(23)\n",
    "\n",
    "\n",
    "\n",
    "# --- Remove those 4 cars from the main dataset ---\n",
    "data = data.drop(top4_highest.index)\n",
    "\n",
    "print(f\"\\nâœ… Removed {len(top4_highest)} rows (highest-priced cars).\")\n",
    "print(f\"Remaining rows after removal: {len(data)}\")\n",
    "\n",
    "# --- Optional: visualize boxplot after removal ---\n",
    "plt.figure(figsize=(6,4))\n",
    "plt.boxplot(data['Price'])\n",
    "plt.axhline(y=upper_limit, color='red', linestyle='--', label=f'Upper Fence ({upper_limit:.0f})')\n",
    "plt.title('Price After Removing Top 4 Highest Cars')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For handling outliers I see top 60 hight car price then I descover 1100 ouliers but not wrong outliers then I do search for hight price that effect data found hight 23 pricess extremly far from main clustring and could effect data   \n",
    "\n",
    "\n",
    "I can not remove or clip ouliers because will effect on data\n",
    "\n",
    "\n",
    " \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "â€¢\tApply encoding, scaling, and discretization if needed. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-- First Drop Columns that no need\n",
    "\n",
    "-- Secound we will see skew for all column and fix it if need \n",
    "\n",
    "-- Third use for encoding Labels , one-hot and ordinal label and use discretization \n",
    "\n",
    "--Forth use for scalling z-score  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-> I will Drop Columns that no need\n",
    "\n",
    "1-Drop Location: \n",
    "\n",
    "2-Drop Description\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import re\n",
    "\n",
    "if 'Location' in data.columns:\n",
    "    data = data.drop('Location', axis=1)\n",
    "    print(\"Location: attribute was dropped successfully because most of Cars in Dubai\")\n",
    "else:\n",
    "    print(\"Location: column not found\")\n",
    "\n",
    "#Make description attribute to lower case \n",
    "data['Description'] = data['Description'].str.lower()\n",
    "\n",
    "Car_Condition ={}\n",
    "Rear_Camera = {}\n",
    "Bluetooth={}\n",
    "Navigation_system={}\n",
    "Leather_seats = {}\n",
    "Adaptive_cruise_control = {}\n",
    "Sunroof = {}\n",
    "\n",
    "\n",
    "\n",
    "#Will convert all feature of car to using one-Hot\n",
    "\n",
    "# Extract condition text after \"Condition:\" until the first \".\"\n",
    "for i, desc in enumerate(data['Description']):\n",
    "    match = re.search(r'condition:\\s*([^.]*)\\.', desc, re.IGNORECASE)\n",
    "    if match:\n",
    "        Car_Condition[i] = match.group(1).strip()\n",
    "    else:\n",
    "        Car_Condition[i] = None  # if not found\n",
    "\n",
    "    if re.search(r'\\brear camera\\b', desc):\n",
    "       Rear_Camera[i]=1\n",
    "    else:\n",
    "       Rear_Camera[i]=0\n",
    "\n",
    "    if re.search(r'\\bbluetooth\\b', desc):\n",
    "        Bluetooth[i]= 1\n",
    "    else:\n",
    "        Bluetooth[i]= 0\n",
    "\n",
    "    if re.search(r'\\bnavigation system\\b', desc):\n",
    "        Navigation_system[i] = 1\n",
    "    else:\n",
    "        Navigation_system[i] = 0\n",
    "\n",
    "    if re.search(r'\\bleather seats\\b', desc):\n",
    "        Leather_seats[i]= 1\n",
    "    else:\n",
    "        Leather_seats[i]= 0\n",
    "\n",
    "    if re.search(r'\\badaptive cruise control\\b', desc):\n",
    "        Adaptive_cruise_control[i]= 1\n",
    "    else:\n",
    "        Adaptive_cruise_control[i]= 0\n",
    "    if re.search(r'\\bsunroof\\b', desc):\n",
    "        Sunroof[i]= 1\n",
    "    else:\n",
    "        Sunroof[i]= 0\n",
    "\n",
    "\n",
    "data['Leather seats'] = data.index.map(Leather_seats)\n",
    "data['Sunroof'] = data.index.map(Sunroof)\n",
    "data['Adaptive cruise control'] = data.index.map(Adaptive_cruise_control)\n",
    "data['Navigation system'] = data.index.map(Navigation_system)\n",
    "data['Bluetooth'] = data.index.map(Bluetooth)\n",
    "data['Rear Camera'] = data.index.map(Rear_Camera)\n",
    "\n",
    "\n",
    "\n",
    "cols = ['Leather seats', 'Sunroof', 'Adaptive cruise control',\n",
    "        'Navigation system', 'Bluetooth', 'Rear Camera']\n",
    "\n",
    "data[cols] = data[cols].fillna(0).astype(int)\n",
    "\n",
    "\n",
    "\n",
    "# Extract condition text after \"Condition:\" until the first \".\"\n",
    "for i, desc in enumerate(data['Description']):\n",
    "    match = re.search(r'condition:\\s*([^.]*)\\.', desc, re.IGNORECASE)\n",
    "    if match:\n",
    "        Car_Condition[i] = match.group(1).strip()\n",
    "    else:\n",
    "        Car_Condition[i] = None  # if not found\n",
    "    \n",
    "\n",
    "\n",
    "data['Car Condition'] = data.index.map(Car_Condition)\n",
    "\n",
    "data['Car Condition'] = data['Car Condition'].fillna('unknown')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print('\\nAbstruct from Description')\n",
    "\n",
    "print('\\n1- Leather seats')\n",
    "print('2- Sunroof')\n",
    "print('3- Adaptive cruise control')\n",
    "print('4- Navigation system')\n",
    "print('5- Bluetooth')\n",
    "print('6- Rear Camera')\n",
    "print('7- Car Condition')\n",
    "\n",
    "\n",
    "\n",
    "if 'Description' in data.columns:\n",
    "    data = data.drop('Description', axis=1)\n",
    "    print(\"\\nDescription: attribute was dropped successfully \")\n",
    "else:\n",
    "    print(\"\\nDescription: column not found\")\n",
    "\n",
    "data.head(2)\n",
    "          "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Descroption of removing columns\n",
    "\n",
    "1- Remove Location attrbuite because major of car in Dubai and all car in UAE country \n",
    " \n",
    "2- For Discreption I get conndition of car in seprate attribute then remove Discription attrbuite."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-- Secound we will see skew for all column and fix it if need "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ColumnName=['Year','Price','Mileage']\n",
    "\n",
    "print(\"----------------\")\n",
    "print(\"Skew Check\") \n",
    "\n",
    "\n",
    "\n",
    "for i in ColumnName:\n",
    "    print(f\"{i}: {data[i].skew()}\")\n",
    "\n",
    "\n",
    "print(\"\\nWe see for price we have right skew because is grater than 1 fix it\")\n",
    "# Before fix skew\n",
    "plt.figure(figsize=(12,5))\n",
    "plt.subplot(1,2,1)\n",
    "sns.histplot(data['Price'], bins=50, kde=True, color='orange')\n",
    "plt.title(f\"Before Fix (Skew = {round(skew(data['Price']), 2)})\")\n",
    "plt.xlabel(\"Price (AED)\")\n",
    "plt.ylabel(\"Count\")\n",
    "\n",
    "data['Price_Skew'] = np.log1p(data['Price'])\n",
    "\n",
    "print(f\"After fix skew is {data['Price_Skew'].skew()}\")\n",
    "# After fix skew\n",
    "plt.subplot(1,2,2)\n",
    "sns.histplot(data['Price_Skew'], bins=50, kde=True, color='teal')\n",
    "plt.title(f\"After Log Fix (Skew = {round(skew(data['Price_Skew']), 2)})\")\n",
    "plt.xlabel(\"Log(Price + 1)\")\n",
    "plt.ylabel(\"Count\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "data.head(1)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Description of Skew \n",
    "\n",
    "I found there is right skew for price of car I fix to be in middle using np.log1p()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-- Third use for encoding Labels , one-hot and ordinal label and use discretization \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "model_labels = {}\n",
    "make_labels = {}\n",
    "\n",
    "make_id = 1\n",
    "\n",
    "# --- Loop through each unique Make ---\n",
    "for make in data['Make'].dropna().unique():\n",
    "    make_labels[make] = make_id\n",
    "   \n",
    "    # Get all models for this Make\n",
    "    models = data[data['Make'].str.lower() == make.lower()]['Model'].dropna().unique()\n",
    "\n",
    "    model_id = 1\n",
    "    for model in models:\n",
    "        key = (make, model)\n",
    "        model_labels[key] = model_id\n",
    "        # print(f\"{model}  -->  {model_id}\")\n",
    "        model_id += 1\n",
    "\n",
    "    make_id += 1\n",
    "\n",
    "# --- Assign Make and Model labels ---\n",
    "data['Make_Label'] = data['Make'].map(make_labels)\n",
    "data['Model_Label'] = data.apply(lambda x: model_labels.get((x['Make'], x['Model'])), axis=1)\n",
    "\n",
    "# --- Encode Body Type ---\n",
    "body_type_Decode = {}\n",
    "\n",
    "body_type = {}\n",
    "\n",
    "i = 1\n",
    "for body in data['Body Type'].dropna().unique():\n",
    "    # print(f\"{body}  -->  {i}\")\n",
    "\n",
    "    body_type_Decode[i]=body\n",
    "    body_type[body] = i\n",
    "    i += 1\n",
    "\n",
    "# print(\"\\nDecoded mapping (Label â†’ Body Type):\", body_type_Decode)\n",
    "\n",
    "i = 1\n",
    "for body in data['Body Type'].dropna().unique():\n",
    "    # print(f\"{body}  -->  {i}\")\n",
    "\n",
    "\n",
    "    body_type[body] = i\n",
    "    i += 1\n",
    "\n",
    "data['BodyType_Label'] = data['Body Type'].map(body_type)\n",
    "\n",
    "\n",
    "Auto_T = {}   # Numeric label for all automatic transmissions\n",
    "Manual_T = {} # Numeric label for all manual transmissions\n",
    "\n",
    "# Enumerate gives both index and value\n",
    "for i, trans in enumerate(data['Transmission']):\n",
    "    if 'Automatic' in str(trans):\n",
    "        Auto_T[trans] = 1\n",
    "        Manual_T[trans] = 0\n",
    "    elif 'Manual' in str(trans):\n",
    "        Auto_T[trans] = 0\n",
    "        Manual_T[trans] = 1\n",
    "    else:\n",
    "        Auto_T[trans] = 0\n",
    "        Manual_T[trans] = 0\n",
    "\n",
    "# Map to new columns\n",
    "data['Transmission_Manual'] = data['Transmission'].map(Manual_T)\n",
    "data['Transmission_Auto'] = data['Transmission'].map(Auto_T)\n",
    "\n",
    "\n",
    "\n",
    "Color = {}\n",
    "i = 1\n",
    "for color in data['Color'].dropna().unique():\n",
    "    # print(f\"{color}  -->  {i}\")\n",
    "    Color[color] = i\n",
    "    i += 1\n",
    "data['Color_Label'] = data['Color'].map(Color)\n",
    "\n",
    "Car_condation = {}\n",
    "i = 1\n",
    "for car in data['Car Condition'].dropna().unique():\n",
    "    # print(f\"{color}  -->  {i}\")\n",
    "    Car_condation[car] = i\n",
    "    i += 1\n",
    "data['Car_Condation_Label'] = data['Car Condition'].map(Car_condation)\n",
    "\n",
    "Fuel = {}\n",
    "i = 1\n",
    "for fuel in data['Fuel Type'].dropna().unique():\n",
    "    # print(f\"{fuel}  -->  {i}\")\n",
    "    Fuel[fuel]=i\n",
    "    i += 1\n",
    "\n",
    "data['Fuel_Label'] = data['Fuel Type'].map(Fuel)\n",
    "bins = [0, 30000, 60000, 110000, 1200000]\n",
    "\n",
    "# bins = [0, 48000, 97000, 177000, 1931000] -- > in KM\n",
    "labels = ['Low', 'Medium', 'High', 'Very High']\n",
    "\n",
    "# Create the categorical bin column\n",
    "data['Mileage_Bin'] = pd.cut(data['Mileage'], bins=bins, labels=labels, include_lowest=True)\n",
    "\n",
    "# Define mapping from text to integer label\n",
    "label_map = {\n",
    "    'Low': 1,\n",
    "    'Medium': 2,\n",
    "    'High': 3,\n",
    "    'Very High': 4\n",
    "}\n",
    "\n",
    "# Convert the text bins into numeric labels\n",
    "data['Mileage_Bin_Label'] = data['Mileage_Bin'].map(label_map).astype(int)\n",
    "\n",
    "bins = [0, 20000, 60000, 150000, 5000000]\n",
    "# bins = [0, 1700, 5000, 12600, 420000] --- > range in kuwait Dinar \n",
    "\n",
    "labels_Car = ['Low', 'Medium', 'High', 'Luxury']\n",
    "\n",
    "# Create price bins in KWD\n",
    "data['Price_Bin'] = pd.cut(data['Price'], bins=bins, labels=labels_Car, include_lowest=True)\n",
    "\n",
    "# Optional numeric encoding\n",
    "label_map = {'Low': 1, 'Medium': 2, 'High': 3, 'Luxury': 4}\n",
    "data['Price_Bin_Label'] = data['Price_Bin'].map(label_map).astype(int)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.width', None)\n",
    "pd.set_option('display.max_rows', None)\n",
    "data.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Description of encoding and discretization:\n",
    "\n",
    "1- Convert all categorical columns in the dataset (such as Make, Model, Color, and Car Condition) into numeric labels.\n",
    "\n",
    "2- Apply one-hot encoding to the Transmission column to represent the categories Automatic and Manual.\n",
    "\n",
    "3- Use discretization (binning) for Price and Mileage to create labeled ranges, and then convert those labels into ordinal numeric values.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-- Forth use for scalling z-score "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<------------------->PUT YOUR CODE HERE FOR Z_SCCORE<----------------->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "â€¢\tStandardize inconsistent formats or categorical values. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "data['Body Type'] = data['Body Type'].str.strip().str.lower()\n",
    "data['Make'] = data['Make'].str.strip().str.lower()\n",
    "data['Model'] = data['Model'].str.strip().str.lower()\n",
    "data['Fuel Type'] = data['Fuel Type'].str.strip().str.lower()\n",
    "data['Color'] = data['Color'].str.strip().str.lower()\n",
    "data['Mileage_Bin'] = data['Mileage_Bin'].str.strip().str.lower()\n",
    "data['Price_Bin'] = data['Price_Bin'].str.strip().str.lower()\n",
    "data['Transmission'] = data['Transmission'].str.strip().str.lower()\n",
    "\n",
    "data['Transmission'] = data['Transmission'].replace({\n",
    "    'automatic transmission': 'automatic',\n",
    "    'a/t': 'automatic',\n",
    "    'manual transmission': 'manual'\n",
    "})\n",
    "print(\"Tranfer all upper case word to lower case in dataset \")\n",
    "print(\"\\nReplace automatic transmission to automatic \")\n",
    "print(\"Replace manual transmission to manual \")\n",
    "print(\"Replace a/t if there is to automatic\")\n",
    "data.head(1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Explenation of Standardize\n",
    "\n",
    "1- Tranfer all upper case word to lower case in dataset \n",
    "\n",
    "2-  Replace automatic transmission to automatic \n",
    "\n",
    "3- Replace manual transmission to manual \n",
    "\n",
    "4- Replace a/t if there is to automatic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "â€¢\tInclude short explanations and before/after plots. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "FILL YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----------> Data Readiness Check <------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4.\tData Readiness Check  \n",
    "\n",
    "â€¢\tConfirm that the dataset is clean and analysis-ready. \n",
    "\n",
    "FILL YOUR ANSWER HERE\n",
    "\n",
    "â€¢\tVisualize transformed features or distributions after cleaning. \n",
    "\n",
    "FILL YOUR ANSWER HERE\n",
    "\n",
    "â€¢\tNote any remaining limitations or challenges. \n",
    "\n",
    "FILL YOUR ANSWER HERE\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5.\tSummary (â‰ˆ 200â€“300 words) \n",
    "\n",
    "â€¢\tSummarize key EDA and preprocessing steps performed.\n",
    "\n",
    "    FILL YOUR ANSWER HERE\n",
    "    \n",
    "â€¢\tExplain how data quality has improved. \n",
    "\n",
    "    FILL YOUR ANSWER HERE\n",
    "\n",
    "â€¢\tList next steps for modeling (classification or clustering in P3). \n",
    "\n",
    "    FILL YOUR ANSWER HERE\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-- Finel Part Decode All data to Origin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2315,
   "metadata": {},
   "outputs": [],
   "source": [
    "#--------- > Decode Part <---------#\n",
    "# #Body Type Decode \n",
    "# body_type_Decode = {\n",
    "#     1: 'Sedan', 2: 'SUV', 3: 'Soft Top Convertible', 4: 'Pick Up Truck',\n",
    "#     5: 'Coupe', 6: 'Crossover', 7: 'Hatchback', 8: 'Hard Top Convertible',\n",
    "#     9: 'Other', 10: 'Utility Truck', 11: 'Sports Car', 12: 'Van', 13: 'Wagon'\n",
    "# }\n",
    "# #Decode Transmission\n",
    "\n",
    "# # decoded_array = np.where(\n",
    "# #     data['Transmission_Auto'] == 1, 'Automatic',\n",
    "# #     np.where(data['Transmission_Manual'] == 1, 'Manual', 'Other')\n",
    "# # )\n",
    "# # print(decoded_array[:5])\n",
    "# # Decoded mapping (Label â†’ Color)\n",
    "\n",
    "# #Decode Color \n",
    "# color_decode = {\n",
    "#     1: 'Black', 2: 'Grey', 3: 'Red', 4: 'White', 5: 'Brown', 6: 'Silver', 7: 'Gold', 8: 'Blue',\n",
    "#     9: 'Other Color', 10: 'Beige', 11: 'Burgundy', 12: 'Orange', 13: 'Green', 14: 'Purple', 15: 'Yellow',16: 'Teal',\n",
    "#     17: 'Tan'\n",
    "# }\n",
    "\n",
    "# #Fuel Decode \n",
    "# fuel_decode = {\n",
    "#     1: 'Gasoline', 2: 'Diesel',\n",
    "#     3: 'Hybrid',4: 'Electric'\n",
    "# }\n",
    "\n",
    "# make_decode = {\n",
    "#     1: 'toyota',2: 'kia',3: 'mini',4: 'nissan',5: 'chevrolet', 6: 'cadillac',7: 'mercedes-benz',8: 'infiniti',\n",
    "#     9: 'mazda',10: 'jeep',11: 'bmw',12: 'porsche',13: 'bentley',14: 'land-rover',15: 'honda',16: 'dodge',\n",
    "#     17: 'rolls-royce',18: 'ford',19: 'hyundai',20: 'lamborghini',21: 'mitsubishi',22: 'aston-martin',\n",
    "#     23: 'gmc',24: 'renault',25: 'volkswagen',26: 'lexus',27: 'suzuki',28: 'lincoln',29: 'audi',30: 'maybach',31: 'peugeot',\n",
    "#     32: 'jaguar',33: 'citroen',34: 'maserati',35: 'ferrari',36: 'volvo',37: 'lotus',38: 'mclaren',39: 'alfa-romeo',\n",
    "#     40: 'fiat',41: 'chrysler',42: 'opel',43: 'tesla',44: 'mercedes-maybach',45: 'geely',46: 'acura',47: 'subaru',\n",
    "#     48: 'genesis',49: 'isuzu',50: 'westfield-sportscars',51: 'mg',52: 'hummer',53: 'skoda',54: 'mercury',\n",
    "#     55: 'rover',56: 'changan',57: 'other-make', 58: 'daihatsu',59: 'jetour',60: 'saab',\n",
    "#     61: 'gac',62: 'haval',63: 'baic',64: 'smart',65: 'morgan'\n",
    "# }\n",
    "\n",
    "# model_decode = {\n",
    "#     1: [  # Make 1 = toyota\n",
    "#         'camry',\n",
    "#         'land-cruiser-76-series',\n",
    "#         'land-cruiser',\n",
    "#         'yaris',\n",
    "#         'hilux',\n",
    "#         'prado',\n",
    "#         'avanza',\n",
    "#         'hiace',\n",
    "#         'rav-4',\n",
    "#         'fortuner',\n",
    "#         # ... continue in SAME order as your list for toyota\n",
    "#     ],\n",
    "#     2: [  # Make 2 = kia\n",
    "#         'sorento',\n",
    "#         'optima',\n",
    "#         'sportage',\n",
    "#         'quoris',\n",
    "#         'rio',\n",
    "#         'telluride',\n",
    "#         'cerato',\n",
    "#         'cadenza',\n",
    "#         # ... rest of kia models in order\n",
    "#     ],\n",
    "#     3: [  # Make 3 = mini\n",
    "#         'cooper',\n",
    "#         'countryman',\n",
    "#         'mini-coupe',\n",
    "#         'clubman'\n",
    "#     ],\n",
    "#     # ... and so on for each make: 4=nissan, 5=chevrolet, etc.\n",
    "# }\n",
    "\n",
    "#  car_condtion_Decode = {\n",
    "#     1: 'engine repaired',2: 'dented door', 3: 'repainted bumper', 4: 'accident history',\n",
    "#     5: 'no damage', 6: 'minor scratches',7: 'unknown'\n",
    "# }\n",
    "\n",
    "#--------- > Decode Part <---------#"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
